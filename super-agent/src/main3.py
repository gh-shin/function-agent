import logging
from flask import Flask, request, jsonify, Response
from datetime import datetime
from dotenv import load_dotenv
import os
import json

# CORS setup
from flask_cors import CORS

# LangChain and OpenAI imports
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# Import sub-agents
# Make sure these files exist in your project directory
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from business_sub_agent import create_business_sub_agent
from life_sub_agent import create_life_sub_agent
from search_sub_agent import create_search_sub_agent

# Import the new stock analysis function
from stock.stock_sub_agent import run_stock_analysis

# Load environment variables from .env file
load_dotenv()

# Initialize Flask app and CORS
app = Flask(__name__)
CORS(app)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# --- Create Sub-Agent Instances ---
# Note: These are assumed to be defined in their respective files
business_agent = create_business_sub_agent()
life_agent = create_life_sub_agent()
search_agent = create_search_sub_agent()

# --- Define Tools for the Orchestrator ---
# This list now includes the new stock_assistant
orchestrator_tools = [
    Tool(
        name="business_assistant",
        func=lambda user_input: business_agent.invoke({"input": user_input}),
        description="ë¹„ì¦ˆë‹ˆìŠ¤, ê²½ì œ, ì¬ë¬´ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì „ë¬¸ê°€.",
    ),
    Tool(
        name="search_assistant",
        func=lambda user_input: search_agent.invoke({"input": user_input}),
        description="ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì „ë¬¸ê°€.",
    ),
    Tool(
        name="life_assistant",
        func=lambda user_input: life_agent.invoke({"input": user_input}),
        description="ì¼ìƒ ìƒí™œ, ì—¬í–‰, ì·¨ë¯¸ ë“± ì¼ë°˜ì ì¸ ì£¼ì œì— ëŒ€í•´ ë‹µë³€í•˜ëŠ” ì „ë¬¸ê°€.",
    ),
    Tool(
        name="stock_assistant",
        func=run_stock_analysis, # Use the new function directly
        description="ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤ ë“± íŠ¹ì • ì£¼ì‹ì˜ ê°€ê²©, ê±°ë˜ëŸ‰, ì¶”ì„¸ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì£¼ì‹ ì „ë¬¸ê°€.",
    ),
]

# --- Create the Super Agent (Orchestrator) ---
def create_super_agent():
    """Creates the main agent executor that orchestrates sub-agents."""
    now = datetime.now().strftime("%Y-%m-%d")
    # Updated prompt to include the new stock_assistant
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""You are a master AI assistant (super agent). Your role is to analyze the user's complex requests and accurately delegate the task to the appropriate specialist assistant.
                
                Here is the list of available specialists:
                - business_assistant: Specialist for business, economy, and finance-related questions.
                - search_assistant: Specialist for performing web searches for the latest information.
                - life_assistant: Specialist for general topics like daily life, travel, and hobbies.
                - stock_assistant: Specialist for answering questions about specific stock prices, volume, and trends.

                Today's date is {now}.
                You must select the most appropriate specialist for the user's query.
                """,
            ),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    llm = ChatOpenAI(model="gpt-4-turbo", temperature=0)
    agent = create_openai_functions_agent(llm, orchestrator_tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=orchestrator_tools, verbose=True)

    return agent_executor

# Create a single instance of the super_agent
super_agent = create_super_agent()

# --- Flask API Endpoints ---
@app.route("/api/ping", methods=["GET"])
def health_check():
    """A simple endpoint to check if the server is running."""
    logging.info("Health check endpoint was called.")
    return jsonify({
        "status": "ok",
        "message": "ğŸ¯ Server is up and running.",
        "timestamp": datetime.now().isoformat()
    }), 200

@app.route("/api/superagent", methods=["POST"])
def superagent_api():
    """The main endpoint to interact with the super agent."""
    data = request.json
    user_query = data.get("query")

    if not user_query:
        logging.warning("Request received without a 'query' field.")
        return Response(
            json.dumps({"error": "The 'query' field is required."}, ensure_ascii=False),
            status=400,
            content_type="application/json"
        )

    logging.info(f"Received query for superagent: '{user_query}'")
    try:
        # Invoke the super agent with the user's query
        result = super_agent.invoke({
            "input": user_query,
            "chat_history": [] # Managing chat history can be implemented here
        })
        
        # The final answer is in the 'output' key
        answer = result.get("output", "Sorry, I couldn't process your request.")
        
        return Response(
            json.dumps({"answer": answer}, ensure_ascii=False),
            status=200,
            content_type="application/json"
        )
    except Exception as e:
        logging.error(f"An error occurred in superagent_api: {e}", exc_info=True)
        return Response(
            json.dumps({"error": f"An internal server error occurred: {str(e)}"}, ensure_ascii=False),
            status=500,
            content_type="application/json"
        )

# --- Main Execution ---
if __name__ == "__main__":
    logging.info("Starting Flask server...")
    # Use debug=False in a production environment
    app.run(host="0.0.0.0", port=8000, debug=True)
